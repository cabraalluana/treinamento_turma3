{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura de arquivos\n",
    "\n",
    "testOriginal = pd.read_csv(\"Arquivos csv/test.csv\")\n",
    "trainOriginal = pd.read_csv(\"Arquivos csv/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções\n",
    "\n",
    "def ordinalEncoding(df, object_cols):\n",
    "    \"\"\"Função que realiza one-hot encode\"\"\"\n",
    "    dfCopia = df\n",
    "    OH_encoder = OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "    OH_cols = pd.DataFrame(OH_encoder.fit_transform(dfCopia[object_cols]))\n",
    "    OH_cols.index = df.index\n",
    "    OH_cols.columns = OH_encoder.get_feature_names_out(object_cols)\n",
    "    dfCopia = dfCopia.drop(object_cols, axis = 1)\n",
    "    OH_X = pd.concat([dfCopia, OH_cols], axis=1)\n",
    "    return OH_X\n",
    "\n",
    "def createPipelines(data, encoder, model, numerical_imputer, categorical_imputer):\n",
    "    \"\"\"\"Essa função produz e avalia pipelines que utilizam estratégias indicadas\n",
    "    nos argumentos passados e, como saída, retorna o resultado da avaliação em porcentagem\"\"\"\n",
    "    # Definindo as features e o target que serão utilizados\n",
    "    X = data.drop(['Survived'], axis = 1)\n",
    "    y = data['Survived']\n",
    "    \n",
    "    train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0, test_size = 0.2)\n",
    "    \n",
    "    # Pré-processamento de dados numéricos\n",
    "    numerical_transformer = numerical_imputer\n",
    "    \n",
    "    # Pré-processamento de dados categóricos\n",
    "    categorical_transformer = Pipeline(steps = [('imputer', categorical_imputer), \n",
    "                                                ('encoder', encoder)])\n",
    "    \n",
    "    # Pré-processamento de pacotes para dados numéricos e categóricos\n",
    "    categorical_cols = list(X.select_dtypes(include = object).columns)\n",
    "    numerical_cols = list(X.select_dtypes(include = [int, float]).columns)\n",
    "    preprocessor = ColumnTransformer(transformers = [('num', numerical_transformer, numerical_cols),\n",
    "                                                     ('cat', categorical_transformer, categorical_cols)])\n",
    "    \n",
    "    # Pré-processamento e modelagem em um pipeline\n",
    "    my_pipeline = Pipeline(steps = [('preprocessor', preprocessor),\n",
    "                                    ('model', model)])\n",
    "    \n",
    "    # Pré-processamento de dados de treinamento, modo de ajuste\n",
    "    my_pipeline.fit(train_X, train_y)\n",
    "    \n",
    "    # Pré-processamento de dados de validação, obter previsões\n",
    "    preds = my_pipeline.predict(val_X)\n",
    "    \n",
    "    # Avalie o modelo\n",
    "    score = accuracy_score(val_y, preds)\n",
    "    \n",
    "    return (score * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informações do banco de dados 'train.csv'\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Sex       891 non-null    object \n",
      " 3   Age       891 non-null    float64\n",
      " 4   SibSp     891 non-null    int64  \n",
      " 5   Parch     891 non-null    int64  \n",
      " 6   Fare      891 non-null    float64\n",
      " 7   Embarked  891 non-null    object \n",
      "dtypes: float64(2), int64(4), object(2)\n",
      "memory usage: 55.8+ KB\n",
      "None\n",
      "\n",
      " Variáveis categóricas: \n",
      " ['Sex', 'Embarked']\n",
      "\n",
      " Variáveis numéricas: \n",
      " ['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
      "\n",
      "Porcentagem das predições que foram acertadas pelo modelo: 82.68%\n"
     ]
    }
   ],
   "source": [
    "# Exercício 8.1\n",
    "# Vou usar a manipulação feita no exercício do cap07 para tratar de valores em falta\n",
    "test = testOriginal.drop(['Cabin', 'Ticket'], axis = 1)\n",
    "train = trainOriginal.drop(['Cabin', 'Ticket'], axis = 1)\n",
    "\n",
    "test['Age'] = test['Age'].fillna(test['Age'].median())\n",
    "train['Age'] = train['Age'].fillna(train['Age'].median())\n",
    "\n",
    "test['Fare'] = test['Fare'].fillna(test['Fare'].median())\n",
    "train['Fare'] = train['Fare'].fillna(train['Fare'].median())\n",
    "\n",
    "test['Embarked'] = test['Embarked'].fillna(test['Embarked'].mode()[0])\n",
    "train['Embarked'] = train['Embarked'].fillna(train['Embarked'].mode()[0])\n",
    "\n",
    "# Name e PassengerId não é uma informação que influencia se a pessoa vai sobreviver,\n",
    "# logo será apagada\n",
    "train = train.drop(['Name', 'PassengerId'], axis = 1)\n",
    "test = test.drop(['Name', 'PassengerId'], axis = 1)\n",
    "\n",
    "# Questão 01\n",
    "print(\"Informações do banco de dados 'train.csv'\\n\")\n",
    "print(train.info())\n",
    "\n",
    "# Obter lista de variáveis categóricas\n",
    "object_cols = list(train.select_dtypes(include = object).columns)\n",
    "\n",
    "print(\"\\n Variáveis categóricas: \\n\", object_cols)\n",
    "\n",
    "# Obter lista de variáveis numéricas\n",
    "num_cols = list(train.select_dtypes(include = [int, float]).columns)\n",
    "\n",
    "print(\"\\n Variáveis numéricas: \\n\", num_cols)\n",
    "\n",
    "newTrain = ordinalEncoding(train, object_cols)\n",
    "newTest = ordinalEncoding(test, object_cols)\n",
    "\n",
    "# Questão 2\n",
    "# Criar variável X, contendo as Features\n",
    "X = newTrain.drop('Survived', axis = 1)\n",
    "\n",
    "# Criar variável y, contendo o target\n",
    "y = newTrain['Survived']\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0, test_size = 0.2)\n",
    "\n",
    "# Treinar random forest com as features e o target de treino\n",
    "modelo_titanic = RandomForestClassifier()\n",
    "\n",
    "# Realizar a predição\n",
    "modelo_titanic.fit(train_X, train_y)\n",
    "\n",
    "predicted_survived = modelo_titanic.predict(val_X)\n",
    "qualidade = accuracy_score(val_y, predicted_survived)\n",
    "print(\"\\nPorcentagem das predições que foram acertadas pelo modelo: {:.2f}%\".format((qualidade*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Porcentagem das predições que foram acertadas pelo modelo Pipelines é: 84.92%\n",
      "\n",
      "Porcentagem das predições que foram acertadas pelo modelo usando o encoder 'OneHotEncoder(handle_unknown='ignore')' e o imputer 'mean': 84.36%\n",
      "\n",
      "Porcentagem das predições que foram acertadas pelo modelo usando o encoder 'OneHotEncoder(handle_unknown='ignore')' e o imputer 'most_frequent': 84.92%\n",
      "\n",
      "Porcentagem das predições que foram acertadas pelo modelo usando o encoder 'OneHotEncoder(handle_unknown='ignore')' e o imputer 'median': 83.80%\n",
      "\n",
      "Porcentagem das predições que foram acertadas pelo modelo usando o encoder 'OneHotEncoder(handle_unknown='ignore')' e o imputer 'constant': 84.36%\n",
      "\n",
      "Porcentagem das predições que foram acertadas pelo modelo usando o encoder 'OrdinalEncoder()' e o imputer 'mean': 83.24%\n",
      "\n",
      "Porcentagem das predições que foram acertadas pelo modelo usando o encoder 'OrdinalEncoder()' e o imputer 'most_frequent': 83.24%\n",
      "\n",
      "Porcentagem das predições que foram acertadas pelo modelo usando o encoder 'OrdinalEncoder()' e o imputer 'median': 82.12%\n",
      "\n",
      "Porcentagem das predições que foram acertadas pelo modelo usando o encoder 'OrdinalEncoder()' e o imputer 'constant': 84.36%\n",
      "\n",
      "A precissão de todos os modelos utilizados nos exercícios do capítulo 8.1 e 8.2 estão bem próximas\n"
     ]
    }
   ],
   "source": [
    "# Exercício 8.2\n",
    "# Questão 01\n",
    "test = testOriginal.drop(['Cabin', 'Ticket', 'Name', 'PassengerId'], axis = 1)\n",
    "train = trainOriginal.drop(['Cabin', 'Ticket', 'Name', 'PassengerId'], axis = 1)\n",
    "\n",
    "test['Fare'] = test['Fare'].fillna(test['Fare'].median())\n",
    "train['Fare'] = train['Fare'].fillna(train['Fare'].median())\n",
    "\n",
    "# Questão 02\n",
    "score = createPipelines(train, \n",
    "                        OneHotEncoder(handle_unknown = 'ignore'), \n",
    "                        RandomForestClassifier(), \n",
    "                        SimpleImputer(strategy = 'median'),\n",
    "                        SimpleImputer(strategy = 'most_frequent'))\n",
    "\n",
    "print(\"\\nPorcentagem das predições que foram acertadas pelo modelo Pipelines é: {:.2f}%\".format((score)))\n",
    "\n",
    "# Questao 3\n",
    "imputers = ['mean', 'most_frequent', 'median', 'constant']\n",
    "encoders = [OneHotEncoder(handle_unknown = 'ignore'), OrdinalEncoder()]\n",
    "\n",
    "# Questão 4\n",
    "for encoder in encoders:\n",
    "    for imputer in imputers:\n",
    "        score = createPipelines(train, \n",
    "                                encoder, \n",
    "                                RandomForestClassifier(), \n",
    "                                SimpleImputer(strategy = imputer),\n",
    "                                SimpleImputer(strategy = 'most_frequent'))\n",
    "        print(\"\\nPorcentagem das predições que foram acertadas pelo modelo usando o encoder '{}' e o imputer '{}': {:.2f}%\".format(encoder, imputer, score))\n",
    "        \n",
    "# Questão 5\n",
    "print(\"\\nA precissão de todos os modelos utilizados nos exercícios do capítulo 8.1 e 8.2 estão bem próximas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Porcentagem das predições que foram acertadas pelo modelo Cross validation e Gradient Boosting foi: 83.84%\n",
      "\n",
      "O algoritimo que se saiu melhor foi o Gradient Boosting\n"
     ]
    }
   ],
   "source": [
    "# Exercicio 8.3\n",
    "# Questão 1 - O modelo que se saiu melhor no teste foi:\n",
    "# encoder: OneHotEncoder e o imputer = 'most_frequent' \n",
    "\n",
    "# Questão 2\n",
    "#Letra c\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0, \n",
    "                                                  test_size = 0.2)\n",
    "\n",
    "my_model = GradientBoostingClassifier(random_state = (0), n_iter_no_change = (100))\n",
    "my_model.fit(train_X, train_y)\n",
    "\n",
    "predictions = my_model.predict(val_X)\n",
    "scores = cross_val_score(my_model, X, y, cv = 5, scoring = 'accuracy')\n",
    "\n",
    "print(\"\\nPorcentagem das predições que foram acertadas pelo modelo Cross validation e Gradient Boosting foi: {:.2f}%\".format(scores.mean()*100))\n",
    "\n",
    "# Letra d\n",
    "print(\"\\nO algoritimo que se saiu melhor foi o Gradient Boosting\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "604d36363eafd9e67c1f556089da69fa54f9731189d50fdd5ef0c173bfd24ffb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
